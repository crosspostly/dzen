/**
 * üé® ZenMaster v4.3 - Image Generator Agent
 * 
 * CRITICAL CHANGE: Extract ACTUAL STORY from article content
 * Not templates, not generic tags
 * EVERY STORY ‚Üí UNIQUE SCENE with specific details, context, emotions
 * 
 * Features:
 * - Extract scene from article LEDE (first 300 chars)
 * - Identify key story elements (who, what, where, why, emotion)
 * - Build SPECIFIC scene description for Gemini
 * - Generate UNIQUE image per story
 * - Fallback on generation failure
 * - Image validation (dimensions, size, format)
 */

import { GoogleGenAI, Modality } from "@google/genai";
import {
  ImageGenerationRequest,
  CoverImageRequest,
  GeneratedImage,
  ExtractedScene,
  PromptComponents,
  ImageValidationResult,
  ImageGenerationConfig
} from "../types/ImageGeneration";
import { PlotBible } from "../types/PlotBible";

export class ImageGeneratorAgent {
  private geminiClient: GoogleGenAI;
  private config: ImageGenerationConfig;
  private fallbackModel = "gemini-2.5-flash-lite";
  private primaryModel = "gemini-2.5-flash-image";

  constructor(apiKey?: string, config?: Partial<ImageGenerationConfig>) {
    const key = apiKey || process.env.GEMINI_API_KEY || process.env.API_KEY || '';
    this.geminiClient = new GoogleGenAI({ apiKey: key });
    
    this.config = {
      aspectRatio: "16:9",
      quality: "high",
      format: "jpeg",
      maxRetries: 2,
      retryDelay: 3000,
      rateLimit: 1,
      enableFallback: true,
      optimizeForZen: true,
      ...config
    };
  }

  /**
   * üé® v4.3: Generate cover image with ACTUAL STORY from article
   * Not hardcoded templates!
   */
  async generateCoverImage(request: CoverImageRequest): Promise<GeneratedImage> {
    console.log(`üé® Generating cover for: "${request.title}"`);

    try {
      // üî• EXTRACT ACTUAL STORY from article lede + content
      const storyContext = this.extractStoryContext(
        request.title,
        request.ledeText,
        request.plotBible
      );
      console.log(`üìñ Story context extracted: ${storyContext.summary}`);

      // üî• Build SPECIFIC scene description from story
      const prompt = this.buildStorySpecificPrompt(storyContext);
      console.log(`üé¨ Story-specific prompt built (${prompt.length} chars)`);

      // Generate with primary model
      const image = await this.generateWithModel(
        this.primaryModel,
        prompt,
        request.articleId
      );

      console.log(`‚úÖ Cover generated for "${request.title}"`);
      return image;

    } catch (error) {
      const errorMsg = (error as Error).message;
      console.warn(`‚ö†Ô∏è  Primary generation failed: ${errorMsg}`);

      if (this.config.enableFallback) {
        console.log(`üîÑ Attempting fallback...`);
        return await this.generateCoverImageFallback(request);
      }

      throw error;
    }
  }

  /**
   * üî• EXTRACT STORY CONTEXT from article content
   * Find: Who, What, Where, When, Why, How, Emotion
   */
  private extractStoryContext(title: string, lede: string, plotBible: PlotBible | undefined) {
    const fullText = `${title}. ${lede}`.toLowerCase();
    const narrator = plotBible?.narrator || { age: 40, gender: 'female', tone: 'confessional' };

    // –ö–¢–û? (Who is the main character and what's their situation?)
    let protagonist = this.extractProtagonist(title, lede, narrator);

    // –ß–¢–û –ü–†–û–ò–ó–û–®–õ–û? (What is the MAIN EVENT/CONFLICT?)
    let mainEvent = this.extractMainEvent(title, lede);

    // –ì–î–ï? (Where does the story take place? What location?)
    let location = this.extractLocation(lede);

    // –ö–û–ì–î–ê? (When? Morning/evening? Past/present?)
    let timeContext = this.extractTimeContext(lede);

    // –ö–ê–ö–ê–Ø –≠–ú–û–¶–ò–Ø? (What emotion defines this story?)
    let emotionalArc = this.extractEmotionalArc(title, lede);

    // –ö–ê–ö–ò–ï –í–ò–î–ò–ú–´–ï –î–ï–¢–ê–õ–ò? (What specific objects/actions are visible?)
    let visibleDetails = this.extractVisibleDetails(title, lede);

    // –§–û–ö–£–° –°–¶–ï–ù–´? (What is the focal point? The key object/action?)
    let focalPoint = this.extractFocalPoint(title, lede, visibleDetails);

    // –ö–¢–û –ü–†–ò–°–£–¢–°–¢–í–£–ï–¢? (Who else is there? Alone or with others?)
    let presenceContext = this.extractPresenceContext(lede);

    return {
      title,
      protagonist,
      mainEvent,
      location,
      timeContext,
      emotionalArc,
      visibleDetails,
      focalPoint,
      presenceContext,
      narrator,
      summary: `${protagonist.name}: ${mainEvent} at ${location} (${emotionalArc.primary})`
    };
  }

  /**
   * üé≠ Extract protagonist details
   */
  private extractProtagonist(title: string, lede: string, narrator: any) {
    const age = narrator.age || 40;
    const appearance = lede.includes('–º–æ–ª–æ–¥–∞—è') ? 'young' :
                      lede.includes('—Å—Ç–∞—Ä–∞—è') ? 'elderly' : 'middle-aged';

    return {
      name: 'Woman', // Generic, focus on emotion
      age,
      appearance,
      state: this.extractPhysicalState(lede),
      relationship: this.extractRelationshipContext(title, lede)
    };
  }

  /**
   * üìñ Extract MAIN EVENT (the core story)
   */
  private extractMainEvent(title: string, lede: string): string {
    const text = `${title}. ${lede}`.toLowerCase();

    // DETECT MAJOR LIFE EVENTS
    if (text.includes('—Ä–∞–∑–≤–æ–¥') || text.includes('–º—É–∂')) {
      if (text.includes('–Ω–µ–Ω–∞–≤–∏–¥') || text.includes('–æ–±–º–∞–Ω') || text.includes('–ø—Ä–µ–¥–∞—Ç–µ–ª')) {
        return 'discovering husband\'s betrayal and divorce';
      }
      return 'dealing with marriage conflict';
    }

    if (text.includes('—Å—ã–Ω') || text.includes('—Ä–µ–±—ë–Ω')) {
      if (text.includes('–ø–æ–º–∏—Ä–∏–ª') || text.includes('–º–∏—Ä')) {
        return 'reconciliation with son after conflict';
      }
      if (text.includes('—Å—Å–æ—Ä–∞') || text.includes('–∫–æ–Ω—Ñ–ª–∏–∫')) {
        return 'conflict with child';
      }
      return 'moment with son';
    }

    if (text.includes('—Å–º–µ—Ä—Ç') || text.includes('—É–º–µ—Ä')) {
      return 'dealing with loss and grief';
    }

    if (text.includes('–ø–æ–±–µ–¥–∞') || text.includes('–ø—Ä–µ–æ–¥–æ–ª') || text.includes('—Å—Ç—Ä–∞—Ö')) {
      if (text.includes('–ø—Ä–µ–æ–¥–æ–ª') || text.includes('–ø–æ–±–µ–¥–∏')) {
        return 'overcoming a deep fear';
      }
      return 'facing personal struggle';
    }

    if (text.includes('–ø–µ—Ä–≤–∞—è –ª—é–±–æ–≤—å') || text.includes('–≤—Å—Ç—Ä–µ—á–∞') || text.includes('–ø—Ä–æ—à–ª–æ–µ')) {
      return 'encountering past love/memory';
    }

    if (text.includes('—Å–ª—É—á–∞–π') || text.includes('–º–æ–º–µ–Ω—Ç') || text.includes('–¥–µ–Ω—å')) {
      return 'critical moment in life';
    }

    return 'life-changing moment';
  }

  /**
   * üìç Extract LOCATION from story
   */
  private extractLocation(lede: string): string {
    const text = lede.toLowerCase();

    // SPECIFIC LOCATIONS mentioned in text
    if (text.includes('–∫–∞—Ñ–µ') || text.includes('–∫–æ—Ñ–µ–π–Ω—è') || text.includes('–±–∞—Ä')) {
      return 'intimate cafe with candlelight';
    }
    if (text.includes('–º–æ—Å—Ç') || text.includes('–Ω–∞–±–µ—Ä–µ–∂–Ω–∞—è') || text.includes('–≤–æ–¥–∞')) {
      return 'bridge over river, evening light';
    }
    if (text.includes('–¥–æ–º–∞') || text.includes('–ø–æ–¥—ä–µ–∑–¥') || text.includes('–ø—Ä–∏—Ö–æ–∂–∞—è')) {
      return 'apartment entrance/hallway';
    }
    if (text.includes('–∫—É—Ö–Ω—è')) {
      return 'kitchen with table';
    }
    if (text.includes('–æ—Ñ–∏—Å') || text.includes('–∞–¥–≤–æ–∫–∞—Ç')) {
      return 'office building';
    }
    if (text.includes('–ø–∞—Ä–∫')) {
      return 'park bench';
    }
    if (text.includes('—É–ª–∏—Ü–∞') || text.includes('–¥–æ–∂–¥—å')) {
      return 'street in rain';
    }
    if (text.includes('–æ–∫–Ω–æ') || text.includes('–≤—ã—Å–æ—Ç') || text.includes('—ç—Ç–∞–∂')) {
      return 'high window overlooking city';
    }
    if (text.includes('–º–µ—Ç—Ä–æ') || text.includes('–≤–æ–∫–∑–∞–ª')) {
      return 'transit station';
    }
    if (text.includes('–º–∞—Å—Ç–µ—Ä—Å–∫') || text.includes('—Å—Ç—É–¥–∏')) {
      return 'artist studio';
    }

    return 'apartment interior';
  }

  /**
   * ‚è∞ Extract TIME CONTEXT
   */
  private extractTimeContext(lede: string): string {
    const text = lede.toLowerCase();

    if (text.includes('—É—Ç—Ä–æ') || text.includes('—Ä–∞—Å—Å–≤–µ—Ç')) return 'morning, soft light';
    if (text.includes('–ø–æ–ª–¥–µ–Ω') || text.includes('–¥–µ–Ω—å')) return 'midday, bright light';
    if (text.includes('–≤–µ—á–µ—Ä') || text.includes('–∑–∞–∫–∞—Ç')) return 'evening, golden light';
    if (text.includes('–Ω–æ—á—å')) return 'night, lamp light';
    if (text.includes('–¥–æ–∂–¥—å') || text.includes('—Å–µ—Ä—ã–π')) return 'rainy day, grey light';
    if (text.includes('—Å–Ω–µ–≥')) return 'snowy weather';

    return 'daytime';
  }

  /**
   * üíî Extract EMOTIONAL ARC
   */
  private extractEmotionalArc(title: string, lede: string): { primary: string; secondary: string[] } {
    const text = `${title}. ${lede}`.toLowerCase();

    let primary = 'thoughtful';
    let secondary: string[] = [];

    // PRIMARY EMOTION
    if (text.includes('–ø–ª–∞—á') || text.includes('—Å–ª—ë–∑') || text.includes('–≥–æ—Ä–µ') || text.includes('–Ω–µ–Ω–∞–≤–∏–¥')) {
      primary = 'grief and pain';
      secondary = ['shock', 'betrayal', 'despair'];
    } else if (text.includes('—Ä–∞–¥–æ—Å—Ç—å') || text.includes('—É–ª—ã–±–∫–∞') || text.includes('—Å—á–∞—Å—Ç–ª–∏')) {
      primary = 'joy and relief';
      secondary = ['hope', 'warmth', 'connection'];
    } else if (text.includes('–æ–±–ª–µ–≥—á–µ–Ω–∏–µ') || text.includes('—Å–ø–æ–∫–æ–π–Ω') || text.includes('–º–∏—Ä')) {
      primary = 'relief and peace';
      secondary = ['quiet happiness', 'acceptance', 'healing'];
    } else if (text.includes('—Å—Ç—Ä–∞—Ö') || text.includes('—Ç—Ä–µ–≤–æ') || text.includes('—É–∂–∞—Å')) {
      primary = 'fear and anxiety';
      secondary = ['uncertainty', 'dread', 'vulnerability'];
    } else if (text.includes('–≥–Ω–µ–≤') || text.includes('–∑–ª–æ—Å—Ç') || text.includes('—è—Ä–æ—Å—Ç')) {
      primary = 'anger and rage';
      secondary = ['indignation', 'determination', 'strength'];
    } else if (text.includes('—Å—Ç—ã–¥') || text.includes('–≤–∏–Ω–∞') || text.includes('–ø–æ–∫–∞—è–Ω–∏–µ')) {
      primary = 'shame and regret';
      secondary = ['introspection', 'vulnerability', 'acceptance'];
    } else if (text.includes('—Ç—Ä–∏—É–º—Ñ') || text.includes('–ø–æ–±–µ–¥–∞') || text.includes('–ø—Ä–µ–æ–¥–æ–ª') || text.includes('—Å–≤–æ–±–æ–¥')) {
      primary = 'triumph and freedom';
      secondary = ['strength', 'determination', 'new beginning'];
    } else if (text.includes('–æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ') || text.includes('–ø—É—Å—Ç–æ—Ç')) {
      primary = 'loneliness and emptiness';
      secondary = ['melancholy', 'introspection', 'loss'];
    } else if (text.includes('nostalgia') || text.includes('–ø—Ä–æ—à–ª–æ–µ') || text.includes('–ø–∞–º—è—Ç—å')) {
      primary = 'nostalgia and memory';
      secondary = ['longing', 'bittersweet', 'reflection'];
    }

    return { primary, secondary };
  }

  /**
   * üëÅÔ∏è Extract VISIBLE DETAILS from story
   */
  private extractVisibleDetails(title: string, lede: string): string[] {
    const text = `${title}. ${lede}`.toLowerCase();
    const details: string[] = [];

    // EMOTIONAL MARKERS (what do we SEE?)
    if (text.includes('—Å–ª—ë–∑') || text.includes('–ø–ª–∞—á')) details.push('tears on cheeks');
    if (text.includes('–∫—Ä–∞—Å–Ω') && text.includes('–≥–ª–∞–∑')) details.push('red puffy eyes');
    if (text.includes('—É–ª—ã–±–∫') || text.includes('—Å–º–µ—Ö')) details.push('genuine smile');
    if (text.includes('–¥—Ä–æ–∂')) details.push('trembling hands');
    if (text.includes('–ø–∞–ª—å—Ü')) details.push('fingers visible and expressive');
    if (text.includes('—Ä—É–∫') && (text.includes('–≥–æ—Ä—è—á') || text.includes('—Ö–æ–ª–æ–¥–Ω'))) details.push('hands that show emotion');

    // OBJECTS
    if (text.includes('–∫–æ–ª—å—Ü–æ') || text.includes('–∫–æ–ª—å—Ü–∞')) details.push('wedding ring prominent / being removed');
    if (text.includes('—á–∞–π') || text.includes('–∫–æ—Ñ–µ')) details.push('cup of tea/coffee');
    if (text.includes('–ø–ª–∞—Ç–æ–∫') || text.includes('—Ç–∫–∞–Ω—å')) details.push('tissue or cloth');
    if (text.includes('—Ñ–æ—Ç–æ') || text.includes('—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ')) details.push('photo or photograph visible');
    if (text.includes('–ø–∏—Å—å–º–æ') || text.includes('–∑–∞–ø–∏—Å–∫–∞')) details.push('letter or note');
    if (text.includes('–ø–∞–ª—å—Ç–æ') || text.includes('–ø–ª–∞—â')) details.push('coat or outer clothing');
    if (text.includes('—á–∞—Å—ã')) details.push('clock or watch visible');
    if (text.includes('–∑–µ—Ä–∫–∞–ª–æ')) details.push('mirror reflection');
    if (text.includes('—Ç–µ–ª–µ—Ñ–æ–Ω')) details.push('phone in hand or on table');
    if (text.includes('—Å–≤–µ—á–∞')) details.push('candlelight');

    // BODY LANGUAGE
    if (text.includes('–ø–ª–µ—á–æ')) details.push('shoulders that convey emotion');
    if (text.includes('–≥–æ–ª–æ–≤–∞')) details.push('head position (down, up, tilted)');
    if (text.includes('—Å–∏–¥–µ—Ç—å') || text.includes('—Å–∏–¥—è')) details.push('sitting posture');
    if (text.includes('—Å—Ç–æ—è—Ç—å') || text.includes('—Å—Ç–æ—è')) details.push('standing posture');
    if (text.includes('–∏–¥—Ç–∏') || text.includes('—Ö–æ–¥–∏—Ç—å')) details.push('movement/walking');

    // CLOTHING/APPEARANCE
    if (text.includes('–≤–æ–ª–æ—Å')) details.push('hair style (neat or disheveled)');
    if (text.includes('–∫—Ä–∞—Å–∏–≤–∞') || text.includes('–Ω–∞—Ä—è–¥–Ω–∞')) details.push('dressed carefully');
    if (text.includes('–Ω–µ–æ–ø—Ä—è—Ç–Ω') || text.includes('—Ä–∞—Å—Ç—Ä—ë–ø–∞–Ω')) details.push('appearance disheveled');

    return details.length > 0 ? details : ['woman, emotional, present in moment'];
  }

  /**
   * üéØ Extract FOCAL POINT (what is the key visual element?)
   */
  private extractFocalPoint(title: string, lede: string, visibleDetails: string[]): string {
    const text = `${title}. ${lede}`.toLowerCase();

    // RING is often the focal point
    if (text.includes('–∫–æ–ª—å—Ü–æ') || text.includes('–ø–∞–ª–µ—Ü')) {
      return 'wedding ring - either on finger being twisted or in hand being removed';
    }

    // TEARS and EYES
    if (text.includes('—Å–ª—ë–∑') || text.includes('–≥–ª–∞–∑') && text.includes('–∫—Ä–∞—Å–Ω')) {
      return 'eyes - red, puffy, full of emotion';
    }

    // SMILE
    if (text.includes('—É–ª—ã–±–∫') || text.includes('—Å–º–µ—Ö')) {
      return 'smile - genuine and warm';
    }

    // HANDS
    if (text.includes('—Ä—É–∫') && text.includes('–¥—Ä–æ–∂')) {
      return 'trembling hands - showing vulnerability';
    }

    // FACE/EXPRESSION
    if (text.includes('–≤—ã—Ä–∞–∂') || text.includes('–ª–∏—Ü')) {
      return 'face - showing core emotion of the story';
    }

    // POSTURE/BODY
    return 'overall posture and body language - telling the emotional story';
  }

  /**
   * üë• Extract presence context (alone? with who?)
   */
  private extractPresenceContext(lede: string): string {
    const text = lede.toLowerCase();

    if (text.includes('–æ–¥–∏–Ω') || text.includes('–æ–¥–Ω–∞') || text.includes('—Å–∞–º–∞')) {
      return 'alone';
    }
    if (text.includes('–º—É–∂')) {
      return 'with husband (tense/conflicted)';
    }
    if (text.includes('—Å—ã–Ω') || text.includes('–¥–æ—á—å') || text.includes('—Ä–µ–±—ë–Ω')) {
      return 'with child';
    }
    if (text.includes('–ø–æ–¥—Ä—É–≥') || text.includes('–¥—Ä—É–≥')) {
      return 'with friend';
    }
    if (text.includes('–º–∞—Ç—å') || text.includes('–º–∞–º–∞')) {
      return 'with mother';
    }

    return 'alone or in private moment';
  }

  /**
   * üèÉ Extract physical state (how is she physically?)
   */
  private extractPhysicalState(lede: string): string {
    const text = lede.toLowerCase();

    if (text.includes('–¥—Ä–æ–∂') || text.includes('—Å—Ç–æ—è–ª–∞') || text.includes('–∑–∞–º–µ—Ä–∑')) {
      return 'frozen, trembling, in shock';
    }
    if (text.includes('—Ä–∞—Å—Å–ª–∞–±') || text.includes('–º–∏—Ä–Ω')) {
      return 'relaxed and peaceful';
    }
    if (text.includes('—Å–ø–µ—à–Ω') || text.includes('—Ç–æ—Ä–æ–ø–ª')) {
      return 'rushed, urgent';
    }
    if (text.includes('—É—Å—Ç–∞–ª')) {
      return 'exhausted';
    }

    return 'present and aware';
  }

  /**
   * üíï Extract relationship context
   */
  private extractRelationshipContext(title: string, lede: string): string {
    const text = `${title}. ${lede}`.toLowerCase();

    if (text.includes('–º—É–∂')) return 'married/dealing with marriage';
    if (text.includes('—Å—ã–Ω') || text.includes('—Ä–µ–±—ë–Ω')) return 'mother';
    if (text.includes('–ª—é')) return 'in love or heartbreak';
    if (text.includes('–æ–¥–∏–Ω–æ–∫')) return 'alone';

    return 'in relationship';
  }

  /**
   * üé¨ BUILD STORY-SPECIFIC PROMPT (not generic template!)
   */
  private buildStorySpecificPrompt(context: any): string {
    // Create a UNIQUE prompt for THIS specific story
    const prompt = `
üé¨ STORY SCENE - Generate image for this specific story:

üìñ STORY:
${context.title}

üé≠ MAIN EVENT:
${context.mainEvent}

üë§ PROTAGONIST:
${context.protagonist.name}, age ${context.protagonist.age}
Emotional state: ${context.protagonist.state}
Relationship context: ${context.protagonist.relationship}
${context.presenceContext !== 'alone' ? `\nWith: ${context.presenceContext}` : ''}

üìç LOCATION & TIME:
Where: ${context.location}
When: ${context.timeContext}

üíî EMOTIONAL TONE:
Primary emotion: ${context.emotionalArc.primary}
Secondary emotions: ${context.emotionalArc.secondary.join(', ')}

üëÅÔ∏è WHAT WE SEE (VISIBLE DETAILS):
${context.visibleDetails.map((d: string) => `‚Ä¢ ${d}`).join('\n')}

üéØ KEY FOCAL POINT:
${context.focalPoint}

üé® VISUAL DIRECTION:
Don't show generic "woman sitting with tea"
Show THIS SPECIFIC MOMENT from the story:
- Capture the EXACT emotion of this scene
- Include visible details that show WHAT HAPPENED
- The focal point should draw attention naturally
- Lighting should match the emotional tone
- Everything in frame should serve the story

üö´ ABSOLUTE RULES:
- NO text, captions, watermarks
- NO filters or Instagram effects
- NO perfect posing (real moment, not posed)
- NO ambiguity (image should clearly show THIS story's emotion)
- NO generic "woman portrait"

‚úÖ SUCCESS:
When viewer sees this image, they immediately FEEL the emotion
They understand SOMETHING HAPPENED
They can sense the CONTEXT without reading
The image matches EXACTLY what the story describes

üéØ TONE GUIDE by emotion:
${this.getToneGuide(context.emotionalArc.primary)}
    `.trim();

    return prompt;
  }

  /**
   * üé® Get tone/style guide based on primary emotion
   */
  private getToneGuide(emotion: string): string {
    const toneGuides: Record<string, string> = {
      'grief and pain': `
GRIEF scene:
- Cold, clinical apartment lighting (no warmth)
- Empty spaces, silence visible
- Body language: frozen, numb, shock
- Eyes: red, empty, distant look
- Hands: trembling or limp
- Focal point: ring on finger or in hand
- Everything feels FINAL and BROKEN
- This moment changed everything
- Show the MOMENT OF REALIZATION`,

      'relief and peace': `
RELIEF scene:
- Warm, intimate lighting (candlelight or soft lamp)
- Cozy enclosed space (cafe, corner, safe place)
- Body language: relaxed, shoulders down, loose
- Eyes: peaceful, maybe a happy tear
- Hands: unclenched, peaceful
- Focal point: smile or calm expression
- Everything feels HEALED and WHOLE
- Show the MOMENT OF ACCEPTANCE`,

      'triumph and freedom': `
TRIUMPH scene:
- Bright, open, expansive (high window, view)
- Space and air visible
- Body language: standing tall, shoulders back, chest open
- Eyes: looking forward, determined
- Hands: strong, confident, free
- Focal point: absence of ring or hand raised
- Everything feels POSSIBLE and NEW
- Show the MOMENT OF EMPOWERMENT`,

      'fear and anxiety': `
FEAR scene:
- Uncertain, shadowy lighting
- Tight, enclosed spaces
- Body language: curled, protective, small
- Eyes: worried, scanning, uncertain
- Hands: clenched or protecting
- Focal point: worried expression or protective gesture
- Everything feels UNCERTAIN and THREATENING
- Show the MOMENT OF VULNERABILITY`,

      'anger and rage': `
ANGER scene:
- Sharp, high contrast lighting
- Tight framing, nowhere to hide
- Body language: tense, ready, confrontational
- Eyes: intense, blazing, direct
- Hands: clenched, ready to act
- Focal point: fierce expression or aggressive gesture
- Everything feels CHARGED and EXPLOSIVE
- Show the MOMENT OF BREAKING POINT`,

      'shame and regret': `
SHAME scene:
- Subdued, introspective lighting
- Small, contained space (looking down)
- Body language: turned inward, small, withdrawn
- Eyes: downcast, avoiding, ashamed
- Hands: covering, protective, hiding
- Focal point: face showing regret or downturned head
- Everything feels HEAVY and BURDENSOME
- Show the MOMENT OF RECKONING`
    };

    return toneGuides[emotion] || 'Neutral scene showing introspection and presence';
  }

  /**
   * Fallback cover generation - SIMPLIFIED
   */
  private async generateCoverImageFallback(request: CoverImageRequest): Promise<GeneratedImage> {
    console.log(`üîÑ Fallback: Generating simplified cover...`);

    const context = this.extractStoryContext(
      request.title,
      request.ledeText,
      request.plotBible
    );

    const fallbackPrompt = `
üé¨ STORY IMAGE:
Title: ${request.title}
Emotion: ${context.emotionalArc.primary}
Location: ${context.location}
Key emotion: Show this emotion clearly

Generate realistic candid scene matching the emotional tone.
No text, no filters, authentic moment.
    `.trim();

    try {
      return await this.generateWithModel(
        this.fallbackModel,
        fallbackPrompt,
        request.articleId
      );
    } catch (error) {
      console.error(`‚ùå Fallback failed:`, (error as Error).message);
      throw error;
    }
  }

  /**
   * Generate image with specified model
   */
  private async generateWithModel(
    model: string,
    prompt: string,
    idForMetadata: string | number
  ): Promise<GeneratedImage> {
    const startTime = Date.now();

    const response = await this.geminiClient.models.generateContent({
      model: model,
      contents: { 
        parts: [{ text: prompt }] 
      },
      config: {
        responseModalities: [Modality.IMAGE],
        temperature: 0.85,
        topK: 40,
        topP: 0.95,
        maxOutputTokens: 1024,
        imageConfig: {
          aspectRatio: "16:9"
        } as any
      }
    });

    if (!response.candidates || response.candidates.length === 0) {
      throw new Error("No candidates in response");
    }

    const candidate = response.candidates[0];
    if (!candidate.content || !candidate.content.parts) {
      throw new Error("No content parts in response");
    }

    let base64Data: string | null = null;
    for (const part of candidate.content.parts) {
      if (part.inlineData) {
        base64Data = part.inlineData.data;
        break;
      }
    }

    if (!base64Data) {
      throw new Error("No image data in response");
    }

    const generatedImage: GeneratedImage = {
      id: `img_${idForMetadata}_${Date.now()}`,
      base64: base64Data,
      mimeType: "image/jpeg",
      width: 1920,
      height: 1080,
      fileSize: Math.ceil(base64Data.length * 0.75),
      generatedAt: Date.now(),
      model: model,
      prompt: prompt,
      metadata: {
        articleId: typeof idForMetadata === 'string' ? idForMetadata : `article_${idForMetadata}`,
        generationAttempts: 1,
        fallbackUsed: model !== this.primaryModel,
      }
    };

    const validation = this.validateImage(generatedImage);
    if (!validation.valid) {
      throw new Error(`Image validation failed: ${validation.errors.join(', ')}`);
    }

    console.log(`‚úÖ Image generated in ${Date.now() - startTime}ms`);
    return generatedImage;
  }

  /**
   * Validate image
   */
  validateImage(image: GeneratedImage): ImageValidationResult {
    const errors: string[] = [];
    const warnings: string[] = [];

    const dimensionsOk = image.width === 1920 && image.height === 1080;
    if (!dimensionsOk) {
      errors.push(`Invalid dimensions: ${image.width}x${image.height}`);
    }

    const sizeOk = image.fileSize > 10000 && image.fileSize < 5000000;
    if (!sizeOk) {
      warnings.push(`Unusual file size: ${image.fileSize} bytes`);
    }

    const formatOk = image.mimeType === "image/jpeg" || image.mimeType === "image/jpg";
    if (!formatOk) {
      errors.push(`Invalid format: ${image.mimeType}`);
    }

    if (!image.base64 || image.base64.length < 100) {
      errors.push("Base64 data missing or too short");
    }

    return {
      valid: errors.length === 0,
      errors,
      warnings,
      metrics: { dimensionsOk, sizeOk, formatOk, aspectRatioOk: true }
    };
  }
}

export const imageGeneratorAgent = new ImageGeneratorAgent();
